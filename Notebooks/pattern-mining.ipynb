{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgNYbxRUBUod"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "from matplotlib.ticker import AutoMinorLocator\n",
        "from matplotlib import gridspec\n",
        "\n",
        "#scaling, normalization\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "from mlxtend.frequent_patterns import association_rules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NyxwtBhBt_a"
      },
      "outputs": [],
      "source": [
        "#caricamento del dataset\n",
        "df = pd.read_csv('words_glasgow.csv')\n",
        "#faccio una copia del dataset in caso di manipolazione dati\n",
        "dfcopy= df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHmyMSuGByaA"
      },
      "source": [
        "#Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx0ioTLpBz02",
        "outputId": "85ef41f4-af5b-4b37-b553-83387829e76d"
      },
      "outputs": [],
      "source": [
        "df2 = df.copy()\n",
        "#new variable \n",
        "df2[\"perceivability\"] = df2[[\"imageability\", \"concreteness\"]].mean(axis=1)\n",
        "\n",
        "df_perc=df2.drop([\"concreteness\",\"imageability\"], axis=1)\n",
        "\n",
        "dfprepro= df_perc.copy()\n",
        "#rename\n",
        "dfprepro=dfprepro.rename(columns={\"gender\": \"masculinity\"})\n",
        "\n",
        "df_missing=dfprepro.copy()\n",
        "\n",
        "#dfprepro.loc[(dfprepro['web_corpus_freq'].isnull() == True), 'web_corpus_freq'] = dfprepro['web_corpus_freq'].mean()\n",
        "\n",
        "#drop missing values\n",
        "dfprepro=dfprepro.dropna()\n",
        "\n",
        "dfprepro[dfprepro['web_corpus_freq'].isnull()]\n",
        "\n",
        "dfprepro[\"web_corpus_log\"] = pd.qcut(dfprepro[\"web_corpus_freq\"], 10) \n",
        "\n",
        "#taglio la variabile web_corpus_freq in tot gruppi\n",
        "\n",
        "dataframe = [dfprepro]\n",
        "\n",
        "for dataset in dataframe:\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 10000) & (dataset[\"web_corpus_freq\"] <= 100000), \"web_corpus_freq\"] = 4\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 100000) & (dataset[\"web_corpus_freq\"] <= 1000000), \"web_corpus_freq\"] = 5\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 1000000) & (dataset[\"web_corpus_freq\"] <= 10000000), \"web_corpus_freq\"] = 6\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 10000000) & (dataset[\"web_corpus_freq\"] <= 100000000), \"web_corpus_freq\"] = 7\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 100000000) & (dataset[\"web_corpus_freq\"] <= 1000000000), \"web_corpus_freq\"] = 8\n",
        "    dataset.loc[dataset[\"web_corpus_freq\"] > 1000000000, \"web_corpus_freq\"] = 9\n",
        "    \n",
        "dfprepro = dfprepro.drop([\"web_corpus_log\",\"word\"], axis=1)\n",
        "\n",
        "\n",
        "#dfprepro.loc[(dfprepro['web_corpus_freq'].isnull() == True), 'web_corpus_freq'] = dfprepro['web_corpus_freq'].mean()\n",
        "dfprepro.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcbrxFe8CGSv"
      },
      "outputs": [],
      "source": [
        "df_pm= dfprepro.copy()\n",
        "#normalization and scaling\n",
        "var_to_scale=['length','aoa',\"arousal\",\"valence\",\"dominance\",\"familiarity\",\"semsize\",\"masculinity\",\"perceivability\"]\n",
        "\n",
        "features = df_pm[var_to_scale]\n",
        "scaler = MinMaxScaler().fit(features.values)\n",
        "features = scaler.transform(features.values)\n",
        "\n",
        "#from 1 to 4\n",
        "df_pm[var_to_scale] = 4*features\n",
        "df_pm.head()\n",
        "#round down\n",
        "df_pm=df_pm.apply(np.floor)\n",
        "\n",
        "df_pm['length'] = df_pm['length'].astype(str) + '_Lenght'\n",
        "df_pm['arousal'] = df_pm['arousal'].astype(str) + '_Arousal'\n",
        "df_pm['valence'] = df_pm['valence'].astype(str) + '_Valence'\n",
        "df_pm['dominance'] = df_pm['dominance'].astype(str) + '_Dominance'\n",
        "df_pm['familiarity'] = df_pm['familiarity'].astype(str) + '_Familiarity'\n",
        "df_pm['aoa'] = df_pm['aoa'].astype(str) + '_Age_of_Acquisition'\n",
        "df_pm['semsize'] = df_pm['semsize'].astype(str) + '_SemSize'\n",
        "df_pm['masculinity'] = df_pm['masculinity'].astype(str) + '_Masculinity'\n",
        "df_pm['web_corpus_freq'] = df_pm['web_corpus_freq'].astype(str) + '_Web_Corpus_Freq'\n",
        "df_pm['perceivability'] = df_pm['perceivability'].astype(str) + '_Perceivability'\n",
        "\n",
        "\n",
        "polysemy_dict = {0: 'Not Polysemy', 1: 'Polysemy'}\n",
        "df_pm['polysemy'] = df_pm['polysemy'].map(polysemy_dict)\n",
        "\n",
        "df_pm.head()\n",
        "\n",
        "X = df_pm.values.tolist()\n",
        "#create a dataframe without polysemy\n",
        "df_no_pol=df_pm.drop('polysemy',axis=1)\n",
        "\n",
        "X_no_pol = df_no_pol.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "sFGKXyE2DjQr",
        "outputId": "3c5bf75f-7590-4cbe-8fb4-2ac48efad16f"
      },
      "outputs": [],
      "source": [
        "#preprocess for mlxtend\n",
        "te=TransactionEncoder()\n",
        "\n",
        "te_ary=te.fit(X_no_pol).transform(X_no_pol)\n",
        "\n",
        "df3=pd.DataFrame(te_ary,columns=te.columns_)\n",
        "\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GhbSgqJEuWZ"
      },
      "source": [
        "# Frequent Itemsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "46Igmeh3ERZQ",
        "outputId": "76815747-fc64-4aa8-8ba6-bc1515358eec"
      },
      "outputs": [],
      "source": [
        "from mlxtend.frequent_patterns import apriori\n",
        "frequent_itemsets = apriori(df3, min_support=0.065,use_colnames=True)\n",
        "\n",
        "frequent_itemsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwWEHkTfE1LG"
      },
      "source": [
        "# Association Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xUV9VvrkE2Zx",
        "outputId": "4f477227-768a-4d66-f7b0-b4cb9c2309da"
      },
      "outputs": [],
      "source": [
        "from mlxtend.frequent_patterns import apriori\n",
        "frequent_itemsets = apriori(df3, min_support=0.065,use_colnames=True)\n",
        "res = association_rules(frequent_itemsets, metric='confidence',min_threshold=0.75)\n",
        "#export to dataframe\n",
        "res1= res[['antecedents','consequents','support','confidence','lift']]\n",
        "#cut at lift threshold\n",
        "res2 = res1[res1['lift']>2.1]\n",
        "#sort\n",
        "df2=res2.sort_values(by =['consequents','lift'],ascending=(True,False),ignore_index=True )\n",
        "#reindex\n",
        "df2.index=df2.index+1\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7RzxkeoM5T1"
      },
      "source": [
        "#Algoritmo di Citraro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "wXBS9cVAKjiQ",
        "outputId": "3c68666c-f101-4945-f181-237882da07fd"
      },
      "outputs": [],
      "source": [
        "!pip install pyfim\n",
        "from fim import apriori\n",
        "#how number of itemsets change with different supports and closed, maximal or all\n",
        "len_max_it = []\n",
        "len_cl_it = []\n",
        "len_all_it = []\n",
        "for i in range(1, 9+1):\n",
        "    max_itemsets = apriori(X_no_pol, target='m', supp=i, zmin=1)\n",
        "    cl_itemsets = apriori(X_no_pol, target='c', supp=i, zmin=1)\n",
        "    all_itemsets = apriori(X_no_pol, target='s', supp=i, zmin=1)\n",
        "    len_max_it.append( len(max_itemsets)  )\n",
        "    len_cl_it.append( len(cl_itemsets) )\n",
        "    len_all_it.append( len(all_itemsets) )\n",
        "    \n",
        "plt.plot(len_max_it, label='maximal')\n",
        "plt.plot(len_all_it, label='all')\n",
        "\n",
        "plt.plot(len_cl_it, label='closed')\n",
        "plt.legend(fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.xlabel('support (%)', fontsize=15)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "3RG1bPX0KuLG",
        "outputId": "3ca1f4b6-b8ac-4fdc-9b77-2e163dcf6171"
      },
      "outputs": [],
      "source": [
        "!pip install pyfim\n",
        "from fim import apriori\n",
        "#how number of itemsets change with different zmin and closed, maximal or all\n",
        "\n",
        "len_max_it = []\n",
        "len_cl_it = []\n",
        "len_all_it = []\n",
        "for i in range(0, 6+1):\n",
        "    max_itemsets = apriori(X_no_pol, target='m', supp=6, zmin=i)\n",
        "    cl_itemsets = apriori(X_no_pol, target='c', supp=6, zmin=i)\n",
        "    len_max_it.append( len(max_itemsets)  )\n",
        "    len_cl_it.append( len(cl_itemsets) )\n",
        "\n",
        "for i in range(0, 6+1):\n",
        "    all_itemsets = apriori(X_no_pol, target='s', supp=6, zmin=i)\n",
        "    len_all_it.append( len(all_itemsets) )\n",
        "\n",
        "    \n",
        "plt.plot(len_max_it, label='maximal')\n",
        "plt.plot(len_all_it, label='all')\n",
        "plt.plot(len_cl_it, label='closed')\n",
        "plt.legend(fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.xlabel('#zmin', fontsize=15)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "iUAywYpVOaH0",
        "outputId": "49bc9094-254b-4cc5-942c-27c4a6149479"
      },
      "outputs": [],
      "source": [
        "!pip install pyfim\n",
        "from fim import apriori\n",
        "rules = apriori(X_no_pol, target='r', supp=6.5, zmin=1, conf=75, report='aScl')\n",
        "len(rules)\n",
        "#export to dataframe\n",
        "df4 = pd.DataFrame(rules, columns=['target','antecedent','supp','supp (%)','conf','lift'])\n",
        "columns_titles = ['antecedent','target','lift','conf','supp (%)','supp']\n",
        "#reindex columns for better reading\n",
        "df4=df4.reindex(columns=columns_titles)\n",
        "#cut at thresholds\n",
        "df4=df4.loc[df4['lift']>1.6]\n",
        "df4=df4.loc[df4['supp (%)']>6.5]\n",
        "#sorting\n",
        "df4=df4.sort_values(by =['target','lift'],ascending=False,ignore_index=True )\n",
        "#reindex rows\n",
        "df4.index=df4.index+1\n",
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfiNwTAdE8_M",
        "outputId": "defd0212-1b18-410f-e5c6-eee1c044bd1f"
      },
      "outputs": [],
      "source": [
        "df4=df4.round(2)\n",
        "\n",
        "print(df4.to_latex())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9-ESJ2goXpkD",
        "outputId": "253eb836-893e-4d61-d256-8cd9c8c8f8e0"
      },
      "outputs": [],
      "source": [
        "df_Familiarity=df4.loc[df4['target']=='3.0_Familiarity']\n",
        "df_Familiarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5JauditErmf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "uLl48vehY5g3",
        "outputId": "39021ce1-2867-404f-96ca-5a6ff4d8baad"
      },
      "outputs": [],
      "source": [
        "df_Valence=df4.loc[df4['target']=='2.0_Valence']\n",
        "df_Valence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "xt81EHc0Y_R4",
        "outputId": "92b7acd0-3a35-4092-94b4-ba8a17f3babb"
      },
      "outputs": [],
      "source": [
        "df_Dominance=df4.loc[df4['target']=='2.0_Dominance']\n",
        "df_Dominance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lCrcibgISWI"
      },
      "source": [
        "## Replacing missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rTrcZG-IVVC"
      },
      "outputs": [],
      "source": [
        "df_only_missing=df_missing[df_missing['web_corpus_freq'].isnull()]\n",
        "df_temp=df_only_missing.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taacpoOdLlJI",
        "outputId": "2d380663-0016-4a8a-c8c1-ea1f5496967b"
      },
      "outputs": [],
      "source": [
        "#scale (come sopra)\n",
        "var_to_scale=['length','aoa',\"arousal\",\"valence\",\"dominance\",\"familiarity\",\"semsize\",\"masculinity\",\"perceivability\"]\n",
        "\n",
        "features = df_only_missing[var_to_scale]\n",
        "scaler = MinMaxScaler().fit(features.values)\n",
        "features = scaler.transform(features.values)\n",
        "\n",
        "\n",
        "df_only_missing[var_to_scale] = 4*features\n",
        "df_only_missing.head()\n",
        "\n",
        "df_only_missing=df_only_missing[var_to_scale].apply(np.floor)\n",
        "\n",
        "#df_only_missing=df_only_missing.drop(labels='web_corpus_freq',axis=1)\n",
        "\n",
        "df_only_missing['length'] = df_only_missing['length'].astype(str) + '_Lenght'\n",
        "df_only_missing['arousal'] = df_only_missing['arousal'].astype(str) + '_Arousal'\n",
        "df_only_missing['valence'] = df_only_missing['valence'].astype(str) + '_Valence'\n",
        "df_only_missing['dominance'] = df_only_missing['dominance'].astype(str) + '_Dominance'\n",
        "df_only_missing['familiarity'] = df_only_missing['familiarity'].astype(str) + '_Familiarity'\n",
        "df_only_missing['aoa'] = df_only_missing['aoa'].astype(str) + '_Age_of_Acquisition'\n",
        "df_only_missing['semsize'] = df_only_missing['semsize'].astype(str) + '_SemSize'\n",
        "df_only_missing['masculinity'] = df_only_missing['masculinity'].astype(str) + '_Masculinity'\n",
        "#df_only_missing['web_corpus_freq'] = df_only_missing['web_corpus_freq'].astype(str) + '_Web_Corpus_Freq'\n",
        "df_only_missing['perceivability'] = df_only_missing['perceivability'].astype(str) + '_Perceivability'\n",
        "\n",
        "#you need to know wich word you are working with\n",
        "df_only_missing['word'] = df_temp['word']\n",
        "\n",
        "\n",
        "X_miss = df_only_missing.values.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rbRq4FG0L62M",
        "outputId": "71d3d380-632f-446f-ac95-73e6187136b1"
      },
      "outputs": [],
      "source": [
        "rules = apriori(X_no_pol, target='r', supp=4, zmin=2, conf=60, report='aScl')\n",
        "\n",
        "#export found rules to dataframe\n",
        "df4 = pd.DataFrame(rules, columns=['target','antecedents','supp','supp (%)','conf','lift'])\n",
        "#reindex columns\n",
        "columns_titles = ['antecedents','target','lift','conf','supp (%)','supp']\n",
        "df4=df4.reindex(columns=columns_titles)\n",
        "#cuts\n",
        "df4=df4.loc[df4['supp (%)']>2]\n",
        "\n",
        "#which one are Web Coprus Freq?\n",
        "df_web4=df4.loc[(df4['target']=='4.0_Web_Corpus_Freq')] \n",
        "df_web5=df4.loc[(df4['target']=='5.0_Web_Corpus_Freq')] \n",
        "df_web6=df4.loc[(df4['target']=='6.0_Web_Corpus_Freq')] \n",
        "df_web7=df4.loc[(df4['target']=='7.0_Web_Corpus_Freq')] \n",
        "df_web8=df4.loc[(df4['target']=='8.0_Web_Corpus_Freq')] \n",
        "df_web9=df4.loc[(df4['target']=='9.0_Web_Corpus_Freq')]\n",
        "#sort and reindex\n",
        "df4=df4.sort_values(by =['target','lift'],ascending=False,ignore_index=True )\n",
        "df4.index=df4.index+1\n",
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "E0jA6BgEvjGZ",
        "outputId": "c4bd5646-b042-4f98-9449-04b59d0c61cf"
      },
      "outputs": [],
      "source": [
        "df_web4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "8bgPwefkvnQx",
        "outputId": "9277b668-bf69-4de1-efb2-bcf7a19f9725"
      },
      "outputs": [],
      "source": [
        "df_web5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jyulb-uvo7W",
        "outputId": "92f870ed-4999-424f-e95c-a8d93dbdefd5"
      },
      "outputs": [],
      "source": [
        "df_web6=df_web6.loc[df_web6['lift']>1.3]\n",
        "df6=df_web6.loc[74]\n",
        "df6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMqU3QSZx0x3",
        "outputId": "cc6943a3-2c52-4065-d25a-447bea9202c2"
      },
      "outputs": [],
      "source": [
        "print(df6.to_latex())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "BGFTu_Qsvq7W",
        "outputId": "47aa5508-1130-4d92-8460-e3db780a05ea"
      },
      "outputs": [],
      "source": [
        "df_web7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "92vATO3qvsiU",
        "outputId": "267fb29a-fdef-466c-8714-5fffa1d4f2a3"
      },
      "outputs": [],
      "source": [
        "df_web8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "znlXivGvvujZ",
        "outputId": "1d17d85a-17d9-4fcf-941e-d9074db85882"
      },
      "outputs": [],
      "source": [
        "df_web9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIb3ey8XPACw",
        "outputId": "25e5efae-ab6c-4953-aa35-2cbf6c653125"
      },
      "outputs": [],
      "source": [
        "#store rules in a dictionary\n",
        "ant_tup=[]\n",
        "web_tup=[]\n",
        "\n",
        "for i in range(len(rules)):\n",
        "    if (rules[i][0]=='4.0_Web_Corpus_Freq' or \n",
        "        rules[i][0]=='5.0_Web_Corpus_Freq' or \n",
        "        rules[i][0]=='6.0_Web_Corpus_Freq' or \n",
        "        rules[i][0]=='7.0_Web_Corpus_Freq' or\n",
        "        rules[i][0]=='8.0_Web_Corpus_Freq' or\n",
        "        rules[i][0]=='9.0_Web_Corpus_Freq'):\n",
        "      if len(rules[i][1])>1: #this ones are cuts at min thresholds (apriori dont work well)\n",
        "        if rules[i][5]>1.3:\n",
        "          ant_tup.append(rules[i][1])\n",
        "          web_tup.append(rules[i][0])\n",
        "\n",
        "ant_list = [list(ele) for ele in ant_tup]\n",
        "web_list = [list(ele) for ele in web_tup]\n",
        "\n",
        "print(ant_list)\n",
        "\n",
        "#create dictionary between antecedents and Web Corpus Value that they imply\n",
        "zip_iterator = zip(ant_tup, web_tup)\n",
        "a_dictionary = dict(zip_iterator)\n",
        "\n",
        "print(a_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "646-g1LFP1ma",
        "outputId": "cd293916-ee5c-4580-de42-a01d7301ea28"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "list_of_tuples= []\n",
        "#per ogni regola trovata con questi tagli\n",
        "for i in range(len(ant_list)):\n",
        "  ru=ant_list[i] #prendo in considerazione gli antecedenti della regola i\n",
        "  for j in range(len(X_miss)):\n",
        "    mi=X_miss[j] #e i valori delle variabili del missing value j\n",
        "    confront=[k for k in mi if k in ru] #interesezione fra mi e ru\n",
        "    #sorting\n",
        "    confront.sort()\n",
        "    ru.sort()\n",
        "\n",
        "    #se l'intersezione fra mi e ru corrisponde con ru \n",
        "    #allora quella regola riguarda quel missing value \n",
        "    if confront==ru:\n",
        "      confront=tuple(confront)\n",
        "      #trovami il valore di Web Corpus che implicava quella regola\n",
        "      value=a_dictionary.get(confront)\n",
        "      #se sta nel dizionario\n",
        "      if value!=None:\n",
        "        #dimmi che parola è\n",
        "        word=mi[-1]\n",
        "        #creo tupla con parola di riferimento e valore di Web Corpus\n",
        "        new_tuple=(word,value)\n",
        "        #fammi una lista con parola e regola\n",
        "        list_of_tuples.append(new_tuple)\n",
        "        #stampami anche gli antecedenti\n",
        "        print(confront)\n",
        "        #contami quante sono le regola trovate che riguardano i miei missing values\n",
        "Counter(list_of_tuples)\n",
        "\n",
        "        #print(\"\\n word:\",mi[-1],value,\"\\n \\n rule:\",confront)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AfpDSKOQhtP"
      },
      "outputs": [],
      "source": [
        "#puoi fare la stessa cosa di sopra col dataframe, ma è più tricky e c'è qualche bug\n",
        "te_ary_rules=te.fit(ant_list).transform(ant_list)\n",
        "\n",
        "df_rules_encoded=pd.DataFrame(te_ary_rules,columns=te.columns_)\n",
        "\n",
        "df_rules_missing=pd.DataFrame()\n",
        "column_names_miss=list(df_miss_encoded.columns.values)\n",
        "\n",
        "\n",
        "#col_names=[list(ele) for ele in row (df == 'True').idxmax(axis=1)[row])]\n",
        "for row in range(len(df_rules_encoded)):\n",
        "  col_names=df_rules_encoded.columns[(df_rules_encoded == True).iloc[row]].values.tolist()\n",
        "  column_names=list(set(column_names_miss).intersection(col_names))\n",
        "  #col_names=(df == 'True').idxmax(axis=1)[row]\n",
        "  #col_names=df_rules_encoded.apply(lambda row: row[row == 'True'].index, axis=1)\n",
        "  #col_name=get_col_name(row)\n",
        "  for row1 in range(len(df_miss_encoded)):\n",
        "    temp=df_miss_encoded.columns[(df_miss_encoded == True).iloc[row1]].values.tolist()\n",
        "    confront=list(set(temp).intersection(column_names))\n",
        "    confront.sort()\n",
        "    column_names.sort()\n",
        "\n",
        "    if confront == column_names:\n",
        "      confront=tuple(confront)\n",
        "      #print(list(map(a_dictionary.get, confront)), temp[-1])\n",
        "      print(\"\\n word:\",temp[-1],a_dictionary.get(confront),\"\\n \\n rule:\",confront)\n",
        "    #df_miss_encoded[df_miss_encoded.loc[row1,column_names]\n",
        "\n",
        "\n",
        "#df_rules_missing=pd.merge(df_miss_encoded, df_rules_encoded, on = column_names, how='inner')\n",
        "#print(df_rules_missing.columns[(df_rules_missing == True).iloc[row]].values.tolist())\n",
        "#df_rules_missing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkGUkR9H2n7r"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
