{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7szRf9AnGzu8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "from matplotlib.ticker import AutoMinorLocator\n",
        "from matplotlib import gridspec\n",
        "\n",
        "#scaling, normalization\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKzd2uRpHAtS"
      },
      "outputs": [],
      "source": [
        "#caricamento del dataset\n",
        "df = pd.read_csv('words_glasgow.csv')\n",
        "#faccio una copia del dataset in caso di manipolazione dati\n",
        "dfcopy= df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_oexxTsHDgA"
      },
      "outputs": [],
      "source": [
        "df2 = df.copy()\n",
        "df2[\"perceivability\"] = df2[[\"imageability\", \"concreteness\"]].mean(axis=1)\n",
        "df_perc=df2.drop([\"concreteness\",\"imageability\"], axis=1)\n",
        "dfprepro= df_perc.copy()\n",
        "dfprepro=dfprepro.rename(columns={\"gender\": \"masculinity\"})\n",
        "dfprepro.loc[(dfprepro['web_corpus_freq'].isnull() == True), 'web_corpus_freq'] = dfprepro['web_corpus_freq'].mean()\n",
        "dfprepro[\"web_corpus_log\"] = pd.qcut(dfprepro[\"web_corpus_freq\"], 10) #taglio la variabile web_corpus_freq in 10 gruppi\n",
        "dataframe = [dfprepro]\n",
        "for dataset in dataframe:\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 10000) & (dataset[\"web_corpus_freq\"] <= 100000), \"web_corpus_freq\"] = 4\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 100000) & (dataset[\"web_corpus_freq\"] <= 1000000), \"web_corpus_freq\"] = 5\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 1000000) & (dataset[\"web_corpus_freq\"] <= 10000000), \"web_corpus_freq\"] = 6\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 10000000) & (dataset[\"web_corpus_freq\"] <= 100000000), \"web_corpus_freq\"] = 7\n",
        "    dataset.loc[(dataset[\"web_corpus_freq\"] > 100000000) & (dataset[\"web_corpus_freq\"] <= 1000000000), \"web_corpus_freq\"] = 8\n",
        "    dataset.loc[dataset[\"web_corpus_freq\"] > 1000000000, \"web_corpus_freq\"] = 9\n",
        "dfprepro = dfprepro.drop([\"web_corpus_log\",\"word\"], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZiCFEvVH9zz"
      },
      "source": [
        "# Preprocess for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxp0DJs2H08p"
      },
      "outputs": [],
      "source": [
        "# per il decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# visualizzarlo\n",
        "from sklearn import tree\n",
        "import pydotplus \n",
        "from IPython.display import Image \n",
        "\n",
        "# evaluazione\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "# hyperparameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "# cross-validation\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-bWKIcrH2EI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AJLaAgVQ66z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1NBUTvPH5YO"
      },
      "outputs": [],
      "source": [
        "df_class_ref = dfprepro.copy()\n",
        "var_to_scale=['aoa',\"arousal\",\"valence\",\"dominance\",\"familiarity\",\"semsize\",\"masculinity\",\"perceivability\"]\n",
        "\n",
        "features = df_class_ref[var_to_scale]\n",
        "scaler = MinMaxScaler().fit(features.values)\n",
        "features = scaler.transform(features.values)\n",
        "\n",
        "df_class_ref[var_to_scale] = features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "3HVyCU8VIKHV",
        "outputId": "0a1fa83c-2cfa-460f-dcca-1de31120115c"
      },
      "outputs": [],
      "source": [
        "df_class_ref"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV_qU-AHBESt"
      },
      "source": [
        "### Arousal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_gVhv6Uyu_m"
      },
      "outputs": [],
      "source": [
        "refvar=\"arousal\"\n",
        "taglio=0.55\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q0fEQYM96U_7",
        "outputId": "af33ae38-e8e5-4619-948f-e545dda24b3c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"not aroused\",\"aroused\"],\n",
        "          feature_names=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "J4S4rFKo7z_w",
        "outputId": "1b0665c5-af39-47cc-cbd5-fbe59cd50842"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "plot_confusion_matrix(clf_dt, X_test, y_test, display_labels=[\"not aroused\",\"aroused\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "fTQ3_cGiptSL",
        "outputId": "3420272f-6e59-45b9-bbf1-0e9d65309f23"
      },
      "outputs": [],
      "source": [
        "y_pred = clf_dt.predict(X_train)\n",
        "y_pred = clf_dt.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBS1bxiV9Qhd"
      },
      "outputs": [],
      "source": [
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ibyq7Kvq-PXk",
        "outputId": "938afe2b-2a81-4a69-c785-e2b41ebbb24a"
      },
      "outputs": [],
      "source": [
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "V9FAquy-ECXC",
        "outputId": "1e777d72-1461-4970-dd23-d941be898b12"
      },
      "outputs": [],
      "source": [
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=0.003)\n",
        "\n",
        "scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "\n",
        "df=pd.DataFrame(data={'tree':range(10), 'accuracy':scores})\n",
        "\n",
        "df.plot(x='tree', y='accuracy',marker='o',linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "X0Fo9gWnFmqI",
        "outputId": "05d5deb3-9c4e-4664-c802-186e4c3ac82d"
      },
      "outputs": [],
      "source": [
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "-yrSgqsqRjMd",
        "outputId": "e45204f6-b71b-4419-c69a-1f8ed50deec3"
      },
      "outputs": [],
      "source": [
        "alpha_results[(alpha_results['alpha']>0.001)\n",
        "&\n",
        "(alpha_results['alpha']<0.005)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB3zD79SsswP"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1iBwQjYTM-G"
      },
      "outputs": [],
      "source": [
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "9hvbqWJYTcMU",
        "outputId": "329b1246-0324-4bed-ea64-dddaad4c1de7"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not aroused','aroused'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "LMNpCCmfURgd",
        "outputId": "5171b9c1-a1ab-4965-dcaf-7966cc17ed12"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"not aroused\",\"aroused\"],\n",
        "          feature_names=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "4I_zrFxy7QQ3",
        "outputId": "4933af9d-9c85-40a6-be65-389513c09b90"
      },
      "outputs": [],
      "source": [
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred,average='weighted'))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zFE4PJHI44x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC73JmyqAjIK"
      },
      "source": [
        "### Valence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NZDmimgCNck"
      },
      "outputs": [],
      "source": [
        "refvar=\"valence\"\n",
        "taglio=0.67\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0pJCpf0hAirj",
        "outputId": "c71dcac6-fc31-4840-bbaa-c0cc0ea656d7"
      },
      "outputs": [],
      "source": [
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "4KU0ZArjCgfK",
        "outputId": "811c7f30-fafa-4d65-a917-aa0708c36e76"
      },
      "outputs": [],
      "source": [
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzfWMWHDCwXx"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "280CVd5OC7jS",
        "outputId": "15219212-5ce7-42db-db8e-72344cbb5485"
      },
      "outputs": [],
      "source": [
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "clf_dt_pruned.classes_\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[str(v) for v in clf_dt_pruned.classes_],\n",
        "          feature_names=X.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "foiAczfaDG-N",
        "outputId": "30beaac4-e370-4ed2-d4d9-2e0aaad0a8ba"
      },
      "outputs": [],
      "source": [
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred,average='weighted'))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not val','val'])\n",
        "\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd186HJlEXjA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-iuPZjMEY0I"
      },
      "source": [
        "### Dominance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TozZjrcQE8Sn"
      },
      "outputs": [],
      "source": [
        "refvar=\"dominance\"\n",
        "taglio=0.57"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JoFwJfVi_d9"
      },
      "outputs": [],
      "source": [
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "TbyPJeJQFK4p",
        "outputId": "050e21b2-fc55-49a4-8c9b-6dfbae157451"
      },
      "outputs": [],
      "source": [
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MposZFSmq_Kt"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B3Kg5rE8F5QS",
        "outputId": "04ae8f15-9831-403c-c553-27d20d1d4469"
      },
      "outputs": [],
      "source": [
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not dominant','dominant'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"not dominant\",\"dominant\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHdG3gnjJF7h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIYuPo8UGP4f"
      },
      "source": [
        "### Familiarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qa8vBtvYk69a"
      },
      "outputs": [],
      "source": [
        "refvar=\"familiarity\"\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "dIYakLJRGXCK",
        "outputId": "4c4b67ce-0177-4196-be61-e689d3e53ba3"
      },
      "outputs": [],
      "source": [
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x7cMb699G_Yw",
        "outputId": "9d0c8191-f858-4e4d-82a9-538638e712d3"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not dominant','dominant'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"not familiar\",\"familiar\"],\n",
        "          feature_names=X.columns,\n",
        "          max_depth=3,\n",
        "          fontsize=7)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "plt.savefig('plot_of_tree.pdf')\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RawQw8vhHEmi"
      },
      "source": [
        "### Semsize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDucieXzoDKG"
      },
      "outputs": [],
      "source": [
        "refvar=\"semsize\"\n",
        "taglio=0.63\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "iGtGPPTiHKv1",
        "outputId": "475ec91c-3dfd-42ca-e611-4784649322fc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2an2gZTlIoAS",
        "outputId": "235cf7d2-5f4b-42ee-da11-f5e0b6a7d110"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['small','big'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"small\",\"big\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5Y0nvhWH8lJ"
      },
      "source": [
        "### Masculinity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "8wBXDmMmIBUl",
        "outputId": "28a9f11a-0fd7-4d06-e631-41cbfa3dc8a7"
      },
      "outputs": [],
      "source": [
        "refvar=\"masculinity\"\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OkW8EKZ8JC5u",
        "outputId": "25a158fd-854e-47f8-8743-a1915f3d2daa"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['feminine','masculine'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"feminine\",\"masculine\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66MYfS5uIDDd"
      },
      "source": [
        "### Polysemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "-iBYvawlIG-x",
        "outputId": "0be3823e-8a0b-41e7-a4ab-8a78b6eb59f5"
      },
      "outputs": [],
      "source": [
        "refvar=\"polysemy\"\n",
        "taglio=0.63\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NdMhWfqRJqfH",
        "outputId": "b8510ea4-a063-4413-9aaa-73adac705e95"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not pol','pol'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"not pol\",\"pol\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred,average='weighted'))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU6vNTapII3X"
      },
      "source": [
        "### Perceivability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjGHzrDXINxg",
        "outputId": "b243785c-2898-4748-e49f-a5f77c9775a0"
      },
      "outputs": [],
      "source": [
        "refvar=\"perceivability\"\n",
        "taglio=0.8\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcBciG_PJ5p3"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not peveivable','perveivable'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"not perceivable\",\"perceivable\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3oQWRqEdbCn"
      },
      "source": [
        "### Age of Aquisition (binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VH9o_P5dhpx"
      },
      "outputs": [],
      "source": [
        "refvar=\"aoa\"\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bks6rogxg4A-"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['younger','older'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"younger\",\"older\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mNpmccFIO6L"
      },
      "source": [
        "### Web Corpus Frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHCx7DvYCZMS"
      },
      "outputs": [],
      "source": [
        "refvar=\"web_corpus_freq\"\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   yerr='std',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8HUU9lMCg3U"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['4','5','6','7','8','9'],\n",
        "                      )\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=['4','5','6','7','8','9'],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred,average=None))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(clf_dt_pruned.predict_proba(X_test))\n",
        "\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "export = pd.DataFrame(report).transpose()\n",
        "\n",
        "print(export.to_latex())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9xYFZ4wxlBr"
      },
      "source": [
        "## 3.2 Classification by KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyuy4FbDi00l"
      },
      "source": [
        "### Age of Aquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg7aPNe8laMx"
      },
      "source": [
        "#### choice of k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHxwdYYElaM1"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "refvar=\"aoa\"\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "k = 4  \n",
        "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
        "Pred_y = neigh.predict(X_test)\n",
        "\n",
        "\n",
        "error_rate = []\n",
        "for i in range(1,100):\n",
        " knn = KNeighborsClassifier(n_neighbors=i)\n",
        " knn.fit(X_train,y_train)\n",
        " pred_i = knn.predict(X_test)\n",
        " error_rate.append(np.mean(pred_i != y_test))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('Error Rate vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Error Rate')\n",
        "print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOpqGFl1laM5"
      },
      "outputs": [],
      "source": [
        "\n",
        "acc = []\n",
        "# Will take some time\n",
        "from sklearn import metrics\n",
        "for i in range(1,40):\n",
        "    neigh = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
        "    yhat = neigh.predict(X_test)\n",
        "    acc.append(metrics.accuracy_score(y_test, yhat))\n",
        "    \n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,40),acc,color = 'blue',linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('accuracy vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Accuracy')\n",
        "print(\"Maximum accuracy:-\",max(acc),\"at K =\",acc.index(max(acc)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIHz7Dzu0BIv"
      },
      "outputs": [],
      "source": [
        "\n",
        "refvar=\"aoa\"\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=error_rate.index(min(error_rate)))\n",
        "clf_knn.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsguLG6y0Pz3"
      },
      "outputs": [],
      "source": [
        "# apply KNN to train set\n",
        "y_pred = clf_knn.predict(X_train)\n",
        "y_pred[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLl1_XTjPrwG"
      },
      "outputs": [],
      "source": [
        "y_train.values[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I8VigKHSAil"
      },
      "outputs": [],
      "source": [
        "print('Accuracy', accuracy_score(y_train, y_pred))\n",
        "print('F1', f1_score(y_train, y_pred, average='weighted'))\n",
        "print( classification_report(y_train, y_pred) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDzMWn4jSNKo"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix for trainset\n",
        "# TP, FN, FP, TN\n",
        "confusion_matrix(y_train, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpzoHbW5SSEq"
      },
      "outputs": [],
      "source": [
        "# apply KNN to test set\n",
        "y_pred = clf_knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f75PBOzMSaWO"
      },
      "outputs": [],
      "source": [
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average='weighted'))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "plot_confusion_matrix(clf_knn,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['younger','older'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJzYg9_JSjSg"
      },
      "outputs": [],
      "source": [
        "y_score = clf_knn.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDlMefNMSkWE"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7okteQpUSsCx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9bGJxv_i5j3"
      },
      "source": [
        "### Valence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uiO_uCDmHbi"
      },
      "source": [
        "#### choice of k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0-_oXPImHbm"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "refvar=\"valence\"\n",
        "taglio=0.67\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "k = 4  \n",
        "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
        "Pred_y = neigh.predict(X_test)\n",
        "\n",
        "\n",
        "error_rate = []\n",
        "for i in range(1,100):\n",
        " knn = KNeighborsClassifier(n_neighbors=i)\n",
        " knn.fit(X_train,y_train)\n",
        " pred_i = knn.predict(X_test)\n",
        " error_rate.append(np.mean(pred_i != y_test))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('Error Rate vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Error Rate')\n",
        "print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV0r9-URmHbt"
      },
      "outputs": [],
      "source": [
        "\n",
        "acc = []\n",
        "# Will take some time\n",
        "from sklearn import metrics\n",
        "for i in range(1,40):\n",
        "    neigh = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
        "    yhat = neigh.predict(X_test)\n",
        "    acc.append(metrics.accuracy_score(y_test, yhat))\n",
        "    \n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,40),acc,color = 'blue',linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('accuracy vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Accuracy')\n",
        "print(\"Maximum accuracy:-\",max(acc),\"at K =\",acc.index(max(acc)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMR42UtQi_SQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "refvar=\"valence\"\n",
        "taglio=0.67\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=error_rate.index(min(error_rate)))\n",
        "clf_knn.fit(X, y)\n",
        "\n",
        "y_pred = clf_knn.predict(X_train)\n",
        "print('Accuracy', accuracy_score(y_train, y_pred))\n",
        "print('F1', f1_score(y_train, y_pred, average='weighted'))\n",
        "print( classification_report(y_train, y_pred) )\n",
        "\n",
        "confusion_matrix(y_train, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLd04X6lDSKp"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred = clf_knn.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average='weighted'))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "plot_confusion_matrix(clf_knn,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not valuable','valuable'])\n",
        "\n",
        "y_score = clf_knn.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USYADQRpi7f6"
      },
      "source": [
        "### Polysemy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dz6O4AmmkgL"
      },
      "source": [
        "#### choice of k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3gw8Zb_mkgP"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "refvar=\"polysemy\"\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "k = 4  \n",
        "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
        "Pred_y = neigh.predict(X_test)\n",
        "\n",
        "\n",
        "error_rate = []\n",
        "for i in range(1,100):\n",
        " knn = KNeighborsClassifier(n_neighbors=i)\n",
        " knn.fit(X_train,y_train)\n",
        " pred_i = knn.predict(X_test)\n",
        " error_rate.append(np.mean(pred_i != y_test))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('Error Rate vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Error Rate')\n",
        "print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JadA2YwgmkgT"
      },
      "outputs": [],
      "source": [
        "\n",
        "acc = []\n",
        "# Will take some time\n",
        "from sklearn import metrics\n",
        "for i in range(1,40):\n",
        "    neigh = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
        "    yhat = neigh.predict(X_test)\n",
        "    acc.append(metrics.average_precision_score(y_test, yhat))\n",
        "    \n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,40),acc,color = 'blue',linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('F1 score vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('F1 Score')\n",
        "print(\"Maximum F1:-\",max(acc),\"at K =\",acc.index(max(acc)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSD9YSaJjrM_"
      },
      "outputs": [],
      "source": [
        "\n",
        "refvar=\"polysemy\"\n",
        "taglio=0.67\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=acc.index(max(acc)))\n",
        "clf_knn.fit(X, y)\n",
        "\n",
        "y_pred = clf_knn.predict(X_train)\n",
        "print('Accuracy', accuracy_score(y_train, y_pred))\n",
        "print('F1', f1_score(y_train, y_pred, average='weighted'))\n",
        "print( classification_report(y_train, y_pred) )\n",
        "\n",
        "confusion_matrix(y_train, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4qkMGsGD7RQ"
      },
      "outputs": [],
      "source": [
        "y_pred = clf_knn.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average='weighted'))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "plot_confusion_matrix(clf_knn,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not polysemic','polysemic'])\n",
        "\n",
        "y_score = clf_knn.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20g-CF0qJsaW"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj8z85dbLKcV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eryMKqdKvD0"
      },
      "source": [
        "### Valence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W97YBvOnK-KZ"
      },
      "outputs": [],
      "source": [
        "refvar='valence'\n",
        "taglio=0.67\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Instantiate model with 10 decision trees\n",
        "model = RandomForestClassifier(n_estimators = 380, random_state = 42)\n",
        "# Train the model on training data\n",
        "ra=model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#TESTING THE MODEL BY PREDICTING ON TEST DATA\n",
        "#AND CALCULATE THE ACCURACY SCORE\n",
        "\n",
        "prediction_test = model.predict(X_test)\n",
        "#print(y_test, prediction_test)\n",
        "\n",
        "#Print the prediction accuracy\n",
        "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_test))\n",
        "#Test accuracy for various test sizes and see how it gets better with more training data\n",
        "\n",
        "#One amazing feature of Random forest is that it provides us info on feature importances\n",
        "# Get numerical feature importances\n",
        "#importances = list(model.feature_importances_)\n",
        "\n",
        "#Let us print them into a nice format.\n",
        "\n",
        "feature_list = list(X.columns)\n",
        "feature_imp = pd.Series(model.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
        "print(feature_imp)\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "plot_confusion_matrix(ra,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not val','val'],\n",
        "                      )\n",
        "\n",
        "y_score = model.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred,average='weighted'))\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_l8XI-WKxS3"
      },
      "source": [
        "### Polysemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW1leXpENrYB"
      },
      "outputs": [],
      "source": [
        "refvar='polysemy'\n",
        "taglio=0.67\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
        "\n",
        "# Instantiate model with 10 decision trees\n",
        "model = RandomForestClassifier(n_estimators = 385, random_state = 42)\n",
        "# Train the model on training data\n",
        "ra=model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#TESTING THE MODEL BY PREDICTING ON TEST DATA\n",
        "#AND CALCULATE THE ACCURACY SCORE\n",
        "\n",
        "prediction_test = model.predict(X_test)\n",
        "#print(y_test, prediction_test)\n",
        "\n",
        "#Print the prediction accuracy\n",
        "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_test))\n",
        "#Test accuracy for various test sizes and see how it gets better with more training data\n",
        "\n",
        "#One amazing feature of Random forest is that it provides us info on feature importances\n",
        "# Get numerical feature importances\n",
        "#importances = list(model.feature_importances_)\n",
        "\n",
        "#Let us print them into a nice format.\n",
        "\n",
        "feature_list = list(X.columns)\n",
        "feature_imp = pd.Series(model.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
        "print(feature_imp)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "plot_confusion_matrix(ra,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not pol','pol']\n",
        "                      )\n",
        "\n",
        "y_score = model.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred,average='weighted'))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkuI0qp0V6oH"
      },
      "source": [
        "### Age of Aquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdb9kvJhV5uJ"
      },
      "outputs": [],
      "source": [
        "refvar='aoa'\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Instantiate model with 10 decision trees\n",
        "model = RandomForestClassifier(n_estimators = 380, random_state = 42)\n",
        "# Train the model on training data\n",
        "ra=model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#TESTING THE MODEL BY PREDICTING ON TEST DATA\n",
        "#AND CALCULATE THE ACCURACY SCORE\n",
        "\n",
        "prediction_test = model.predict(X_test)\n",
        "#print(y_test, prediction_test)\n",
        "\n",
        "#Print the prediction accuracy\n",
        "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_test))\n",
        "#Test accuracy for various test sizes and see how it gets better with more training data\n",
        "\n",
        "#One amazing feature of Random forest is that it provides us info on feature importances\n",
        "# Get numerical feature importances\n",
        "#importances = list(model.feature_importances_)\n",
        "\n",
        "#Let us print them into a nice format.\n",
        "\n",
        "feature_list = list(X.columns)\n",
        "feature_imp = pd.Series(model.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
        "print(feature_imp)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "plot_confusion_matrix(ra,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['younger','older']\n",
        "                      )\n",
        "\n",
        "y_score = model.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred,average='weighted'))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ5yXru3A-Ha"
      },
      "source": [
        "### Out of bag error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdaPR8pWAxyj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import OrderedDict\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "refvar='valence'\n",
        "taglio=0.67\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "\n",
        "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
        "# support for parallelized ensembles but is necessary for tracking the OOB\n",
        "# error trajectory during training.\n",
        "ensemble_clfs = [\n",
        "    (\n",
        "        \"RandomForestClassifier, max_features='sqrt'\",\n",
        "        RandomForestClassifier(\n",
        "            warm_start=True,\n",
        "            oob_score=True,\n",
        "            max_features=\"sqrt\",\n",
        "            random_state=RANDOM_STATE,\n",
        "        ),\n",
        "    ),\n",
        "    (\n",
        "        \"RandomForestClassifier, max_features='log2'\",\n",
        "        RandomForestClassifier(\n",
        "            warm_start=True,\n",
        "            max_features=\"log2\",\n",
        "            oob_score=True,\n",
        "            random_state=RANDOM_STATE,\n",
        "        ),\n",
        "    ),\n",
        "    (\n",
        "        \"RandomForestClassifier, max_features=None\",\n",
        "        RandomForestClassifier(\n",
        "            warm_start=True,\n",
        "            max_features=None,\n",
        "            oob_score=True,\n",
        "            random_state=RANDOM_STATE,\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
        "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
        "\n",
        "# Range of `n_estimators` values to explore.\n",
        "min_estimators = 100\n",
        "max_estimators = 1000\n",
        "\n",
        "for label, clf in ensemble_clfs:\n",
        "    for i in range(min_estimators, max_estimators + 1, 5):\n",
        "        clf.set_params(n_estimators=i)\n",
        "        clf.fit(X, y)\n",
        "\n",
        "        # Record the OOB error for each `n_estimators=i` setting.\n",
        "        oob_error = 1 - clf.oob_score_\n",
        "        error_rate[label].append((i, oob_error))\n",
        "\n",
        "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
        "for label, clf_err in error_rate.items():\n",
        "    xs, ys = zip(*clf_err)\n",
        "    plt.plot(xs, ys, label=label)\n",
        "\n",
        "plt.xlim(min_estimators, max_estimators)\n",
        "plt.xlabel(\"n_estimators\")\n",
        "plt.ylabel(\"OOB error rate\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtOV2xcwkieW"
      },
      "source": [
        "## Entropy (Decision Tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6mq9Cs_mAHQ"
      },
      "source": [
        "### Age of Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaD1QAxKkpNV"
      },
      "outputs": [],
      "source": [
        "refvar=\"aoa\"\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='entropy',random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   yerr='std',\n",
        "                   marker='o',\n",
        "                   linestyle='-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqcc6YmQmYda"
      },
      "outputs": [],
      "source": [
        "alpha_results[(alpha_results['alpha']>0.002)\n",
        "&\n",
        "(alpha_results['alpha']<0.004)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjw0-jWHmZUQ"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "print(ideal_ccp_alpha)\n",
        "\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['young','old'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"young\",\"old\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udVEPwoxmk0F"
      },
      "source": [
        "### Polysemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CJWWMGQnOmy"
      },
      "outputs": [],
      "source": [
        "refvar=\"polysemy\"\n",
        "taglio=0.6\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='entropy',random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   yerr='std',\n",
        "                   marker='o',\n",
        "                   linestyle='-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDK24VrrnUQc"
      },
      "outputs": [],
      "source": [
        "alpha_results[(alpha_results['alpha']>0.002)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itixKtSwnZEP"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "print(ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not polysemic','polysemic'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"not polysemic\",\"polysemic\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRq66UP3ofYX"
      },
      "source": [
        "### Valence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70Pem2foohks"
      },
      "outputs": [],
      "source": [
        "refvar=\"valence\"\n",
        "taglio=0.67\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "y_up_index = y >= taglio\n",
        "\n",
        "y[y_up_index]=1\n",
        "\n",
        "y_zero_index = y < taglio\n",
        "\n",
        "y[y_zero_index]=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   yerr='std',\n",
        "                   marker='o',\n",
        "                   linestyle='-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6grYOGaXot5A"
      },
      "outputs": [],
      "source": [
        "alpha_results[(alpha_results['alpha']>0.0025)\n",
        "&\n",
        "(alpha_results['alpha']<0.0035)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hKLtWoWo0pH"
      },
      "outputs": [],
      "source": [
        "indexmax = alpha_results[['mean_accuracy']].idxmax()\n",
        "\n",
        "maxalpha=alpha_results.loc[indexmax,'alpha']\n",
        "\n",
        "ideal_ccp_alpha = float(maxalpha)\n",
        "\n",
        "print(ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['not valuable','valuable'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=[\"not valuable\",\"valuable\"],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_score = clf_dt_pruned.predict_proba(X_test)\n",
        "\n",
        "fpr, tpr, th = roc_curve(y_test, y_score[:,1])\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='$AUC$ = %.3f' % (roc_auc))\n",
        "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "\n",
        "plt.tick_params(axis='both', which='major', labelsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_8IXKsKRLi6"
      },
      "source": [
        "# Multisplit target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbpC-outROSy"
      },
      "outputs": [],
      "source": [
        "df_class_ref = dfprepro.copy()\n",
        "dataframe = [df_class_ref]\n",
        "for dataset in dataframe:\n",
        "    dataset.loc[(dataset[\"aoa\"] > 1) & (dataset[\"aoa\"] <= 2), \"aoa\"] = 1\n",
        "    dataset.loc[(dataset[\"aoa\"] > 2)& (dataset[\"aoa\"] <= 3), \"aoa\"] = 2\n",
        "    dataset.loc[(dataset[\"aoa\"] > 3)& (dataset[\"aoa\"] <= 4), \"aoa\"] = 3\n",
        "    dataset.loc[(dataset[\"aoa\"] > 4)& (dataset[\"aoa\"] <= 5), \"aoa\"] = 4\n",
        "    dataset.loc[(dataset[\"aoa\"] > 5)& (dataset[\"aoa\"] <= 6), \"aoa\"] = 5\n",
        "    dataset.loc[(dataset[\"aoa\"] > 6)&( dataset[\"aoa\"] <= 7), \"aoa\"] = 6\n",
        "    dataset.loc[(dataset[\"aoa\"] > 7), \"aoa\"] = 7\n",
        "df_class_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o9IsyW1RUDe"
      },
      "outputs": [],
      "source": [
        "var_to_scale=[\"arousal\",\"valence\",\"dominance\",\"familiarity\",\"semsize\",\"masculinity\",\"perceivability\"]\n",
        "\n",
        "features = df_class_ref[var_to_scale]\n",
        "scaler = MinMaxScaler().fit(features.values)\n",
        "features = scaler.transform(features.values)\n",
        "\n",
        "df_class_ref[var_to_scale] = features\n",
        "df_class_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT_c-KVsRgUH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16cC2XXF-eeS"
      },
      "source": [
        "### Age of Aquisition (DT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MB2eYM2-nvg"
      },
      "outputs": [],
      "source": [
        "refvar=\"aoa\"\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42)\n",
        "\n",
        "clf_dt = clf_dt.fit(X_train, y_train)\n",
        "\n",
        "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "clf_dts=[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "  clf_dt.fit(X_train, y_train)\n",
        "  clf_dts.append(clf_dt)\n",
        "\n",
        "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
        "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
        "\n",
        "fig, ax =plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas,train_scores, marker ='o',label='train',drawstyle='steps-post')\n",
        "\n",
        "ax.plot(ccp_alphas,test_scores, marker ='o',label='test',drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "alpha_loop_values =[]\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "  clf_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=0, ccp_alpha=ccp_alpha)\n",
        "  scores= cross_val_score(clf_dt,X_train,y_train, cv=10)\n",
        "  alpha_loop_values.append([ccp_alpha,np.mean(scores), np.std(scores)])\n",
        "\n",
        "alpha_results = pd.DataFrame(alpha_loop_values,\n",
        "                               columns=['alpha','mean_accuracy','std'])\n",
        "  \n",
        "alpha_results.plot(x='alpha',\n",
        "                   y='mean_accuracy',\n",
        "                   marker='o',\n",
        "                   linestyle='--')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-EFh66k_gcN"
      },
      "outputs": [],
      "source": [
        "alpha_results[(alpha_results['alpha']>0.0015)\n",
        "&\n",
        "(alpha_results['alpha']<0.0022)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tskcQsc_jM4"
      },
      "outputs": [],
      "source": [
        "ideal_ccp_alpha = 0.001858\n",
        "\n",
        "ideal_ccp_alpha = float(ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1,random_state=42, ccp_alpha=ideal_ccp_alpha)\n",
        "\n",
        "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)\n",
        "\n",
        "plot_confusion_matrix(clf_dt_pruned,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['0-2','2-4','4-6','6-8','8-10','10-12'])\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(clf_dt_pruned,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          class_names=['0-2','2-4','4-6','6-8','8-10','10-12'],\n",
        "          feature_names=X.columns)\n",
        "\n",
        "y_pred = clf_dt_pruned.predict(X_train)\n",
        "y_pred = clf_dt_pruned.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred,average=None))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(clf_dt_pruned.predict_proba(X_test))\n",
        "\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "export = pd.DataFrame(report).transpose()\n",
        "\n",
        "print(export.to_latex())\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afXrwer3qpkM"
      },
      "source": [
        "### Age of Acquisition (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zqL_jH6qzF_"
      },
      "source": [
        "#### choice of k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOg73ylEqoq1"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "refvar=\"aoa\"\n",
        "\n",
        "X=df_class_ref.drop(refvar,axis=1).copy()\n",
        "\n",
        "y=df_class_ref[refvar].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "k = 4  \n",
        "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
        "Pred_y = neigh.predict(X_test)\n",
        "\n",
        "\n",
        "error_rate = []\n",
        "for i in range(1,100):\n",
        " knn = KNeighborsClassifier(n_neighbors=i)\n",
        " knn.fit(X_train,y_train)\n",
        " pred_i = knn.predict(X_test)\n",
        " error_rate.append(np.mean(pred_i != y_test))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('Error Rate vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Error Rate')\n",
        "print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6crxEa-rhUT"
      },
      "outputs": [],
      "source": [
        "clf_knn = KNeighborsClassifier(n_neighbors=14)\n",
        "clf_knn.fit(X, y)\n",
        "\n",
        "y_pred = clf_knn.predict(X_train)\n",
        "print('Accuracy', accuracy_score(y_train, y_pred))\n",
        "print('F1', f1_score(y_train, y_pred, average='weighted'))\n",
        "print( classification_report(y_train, y_pred) )\n",
        "\n",
        "confusion_matrix(y_train, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbgsJISVrp8p"
      },
      "outputs": [],
      "source": [
        "y_pred = clf_knn.predict(X_test)\n",
        "\n",
        "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('F1-score %s' % f1_score(y_test, y_pred, average='weighted'))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "plot_confusion_matrix(clf_knn,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      display_labels=['0-2','2-4','4-6','6-8','8-10'])\n",
        "\n",
        "y_score = clf_knn.predict_proba(X_test)\n",
        "\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "export = pd.DataFrame(report).transpose()\n",
        "\n",
        "print(export.to_latex())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "N_l8XI-WKxS3",
        "OkuI0qp0V6oH",
        "rZ5yXru3A-Ha",
        "h6mq9Cs_mAHQ",
        "udVEPwoxmk0F",
        "oRq66UP3ofYX",
        "afXrwer3qpkM",
        "5zqL_jH6qzF_"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
